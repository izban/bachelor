\section{Наибольшая общая абелева подстрока}
% Описываешь задачу

\subsection{Общий алгоритм}

Отметим, что нас интересует детерменированный алгоритм решения задачи. Известно несколько недетерменированных решений, на практике работающих достаточно быстро, но они не являются темой исследования данной работы.

Будем подходить к лучшему решению по шагам от самого простого, на каждом шаге оптимизируя какую-то часть алгоритма, для лучшего понимания.

\subsubsection{$\langle \mathcal{O}(n^2 \log \sigma), \mathcal{O}(n \log \sigma) \rangle$ w.h.p}

Будем перебирать длину $l$ и проверять, есть ли общая абелева подстрока длины $l$.
План: построить $\mathcal{P}(t)$ для всех подстрок $t$ длины $l$ строк $a$ и $b$, потом понять, есть ли две строки с одинаковым $\mathcal{P}(t)$.

Будем строить векторы $P(t)$ для всех подстрок длины $l$ строк $a$ и $b$ по очереди, переходя от одной подстроки к следующей. Для этого нужно уметь удалять первый символ текущей строки и дописывать в конец новый символ. Расширим алфавит на один символ, добавив разделитель $\$$, нигде ранее не встречающийся, и будем идти скользящим окном длины $l$ по строке $a\$b$.

Хранить векторы $P(t)$ будем в персистентном массиве, реализованном на персистентном дереве отрезков. Для того, чтобы перейти к следующей подстроке, нужно уменьшить значение в одной ячейке на 1, и увеличить значение в другой ячейке на 1.

Для того, чтобы научиться сравнивать на равенство две вершины дерева, соответствующие двум векторам $P(t)$, будем при построении считать некоторое число $h(v)$~--- класс эквивалентности вершины. Этот класс эквивалентности будет соответствовать набору значений на подотрезке, соответствующему этой вершине~--- две вершины в одном классе эквивалентности, если они соответствуют одному и тому же подотрезку символов, и количество вхождений каждого символа у них одинаково.

Будем поддерживать хешмап, в котором для пары чисел $\langle h_1, h_2 \rangle$ хранится класс эквивалетности пары этих чисел, если она уже встречалась. Чтобы посчитать хеш для листа, проверим класс эквивалентности у пары $\langle -pos, val \rangle$, где $pos$~--- номер символа, соответствующего этому листу, а $val$~--- значение, записанное в этой вершине. Такая пара, с отрицательным $-pos$, выбирается для того, чтобы избежать коллизии со внутренними вершинами, характеристиками которых являются пары неотрицательных чисел~--- пара уже посчитанных классов эквивалентности сыновей $\langle h(v_l), h(v_r) \rangle$. Когда нам нужно узнать хеш пары $\langle h_1, h_2 \rangle$, смотрим в хешмап: если там есть элемент с таким ключом, то соответствующий класс эквивалентности уже посчитан, иначе кладем туда новый элемент с таким ключом и значением, равным размеру хешмапа. Значения всех хешей таким образом будут принимать значения от $0$ до $MapSize - 1$.

Таким образом, после подсчета класса эквивалентности каждой вершины, для всех подстрок длины $l$ первой и второй строки можно выписать их классы эквивалентности, и нужно проверить, есть ли в двух массивах одинаковое число. Поскольку все значения имеют порядок $\mathcal{O}(n \log \sigma)$, это можно сделать используя сортировку подсчетом.

Время работы~--- $n$ итераций по $l$, и $\mathcal{O}(n \log \sigma)$ операций для каждой длины: каждая вершина дерева отрезков создается за $\mathcal{O}(1)$ w.h.p. используя хешмап. Расходуемая память $\mathcal{O}(n \log \sigma)$ на хранение дерева отрезков и хешмапа.


\subsubsection{$\langle \mathcal{O}(n^2 \log \sigma), \mathcal{O}(n^2) \rangle$ deterministic}

Посмотрим внимательнее на персистентное дерево отрезков из предыдущего решения. Это ациклический ориентированный граф, в котором каждая вершина имеет свой уровень (глубину) от $1$ до $\log \sigma$, при чем на каждой глубине по $\mathcal{O}(n)$ вершин.

Будем считать классы эквивалентности всех вершин, поднимаясь по уровням от листьев к корням, используя один хешмап размера $\mathcal{O}(n^2)$, который умеем очищать за $\mathcal{O}(1)$. Под хешмапом здесь и далее я подразумеваю просто массив на $\mathcal{O}(n^2)$ элементов с пометкой последнего изменения для возможности обнуления за $\mathcal{O}(1)$.

В этом решении класс эквивалентности будет будет иметь не сквозную нумерацию среди всех вершин дерева, как в предыдущем решении, а иметь отдельную нумерацию для каждого уровня вершин дерева.

База: посчитать классы эквивалентности листьев. Класс эквивалентности листа, как и в прошлом пункте, $h(\langle -pos, val \rangle)$, где и $pos$, и $val$ принимают значения порядка $\mathcal{O}(n)$. Поэтому можно пройти по всем листам в дереве, и посчитать классы, обращаясь к хешмапу напрямую и спрашивая, был ли уже такой же лист, и какой у него класс эквивалентности. Для того, чтобы обойти все листы за их количество, при построении дерева можно в каждый лист складывать ссылку на новый лист, который появляется в следующей версии дерева отрезков.

Переход: посчитан класс эквивалентности всех вершин более глубокого уровня. Обратим внимание, что поскольку на каждой глубине $\mathcal{O}(n)$ вершин, классы этих вершин так же будут принимать значения $\mathcal{O}(n)$. Поэтому мы можем очистить хешмап и точно так же, как и для листьев, считать значение класса, к которому относится вершина, проверяя, была ли уже такая пара $\langle h(v_l), h(v_r) \rangle$.

Таким образом, мы построили дерево и посчитали хеши всех вершин за $\langle n^2 \log \sigma, n^2 \rangle$ полностью детерменированно.


\subsubsection{$\langle \mathcal{O}(n^2 \log \sigma), \mathcal{O}(n) \rangle$ deterministic}

Начнем с того, что на хранение дерева отрезков у нас сейчас уходит $n \log \sigma$ памяти, это много. Чтобы уменьшить потребление памяти, можно использовать технику \textbf{limited node copying}. Краткое введение, которое будет необходимо для дальнейшего понимания алгоритма: %TODO где прочитать про эту технику?

Вместо того, чтобы после пересоздания очередного листа пересоздавать весь путь до корня, будем хранить в каждой вершине дополнительный указатель, изначально нулевой. При изменении значения в листе будем подниматься по предкам, пока у предка дополнительный указатель уже занят, и создавать в этом случае новую вершину. Когда мы стоим в вершине и знаем, что один из ее сыновей был изменен, а дополнительный указатель еще не занят, просто установим этот дополнительный указатель на новую версию этого сына и подпишем текущим глобальным временем. После такого изменения все еще несложно обратиться к какой-то версии дерева отрезков: нужно просто при переходе к сыновьям при выборе, куда спускаться, посмотреть, не нужно ли идти по дополнительному указателю.

Можно доказать, что таким образом построенное дерево занимает $\mathcal{O}(n)$ памяти, используя амортизационный анализ, но не будем об этом. 

Подсчет классов эквивалентности для листьев и внутренних вершин в этом решении отличается.

База: подсчет классов для листьев. Будем считать классы для листьев группами, для каждой позиции все листья, соответствующие этой позиции в массиве, вместе. Будем поддерживать счетчик $ch$~--- первый еще не использованный номер класса эквивалентности. Фиксировав, какую позицию мы сейчас обрабатываем, просто обойдем все листья с этой позицией (для этого можно хранить в каждом листе ссылку на предыдущий лист этой позиции), и листу со значением $val$ присвоим хеш $ch+val$. после чего увеличим $ch$ на $maxValue_{pos}+1$, где $maxValue_{pos}$~--- наибольшее значение, которое было в ячейке $pos$ в одной из версий дерева отрезков. Мы знаем $maxValue_{pos}$ для каждой позиции, и можно заметить, что количество классов эквивалентности на этом уровне $\mathcal{O}(n)$, поскольку $\sum \limits_{pos=0}^{\sigma} maxValue_{pos} = \mathcal{O}(n)$.

Переход: посчитали классы для всех (даже больше, чем для всех вершин, об этом далее) вершин на предыдущем уровне. Кроме класса вершины мы записываем не только эту вершину, а еще и все ее копии во все времена, которые мы не создавали явно в дереве отрезков (при переходе на послеследующий уровень их можно безопасно удалить, чтобы сохранить линейную память). Чтобы получить для вершины список всех времен, когда она должна была бы существовать без сжатия, нужно просто взять список всех времен всех трех ее сыновей и смерджить, это делается за линейное время, поскольку они уже отсортированы. 

Следующее, что нужно сделать~--- сгруппировать все вершины с одинаковым $h(v_l)$ в одну группу, и обработать их вместе, чтобы назначить им соответствующие классы эквивалентности. Пусть у очередной вершины (для каждого варианта глобального времени, которое в ней интересно) классы сыновей $h(v_l)$ и $h(v_r)$. Запишем в вектор с номером $h(v_l)$ напоминание: нужно посчитать $h(\langle h_1, h_2 \rangle)$ и записать его в текущую вершину $v$. После того, как сделали это для всех вершин текущего уровня, можно перебирать $h(v_l)$, очищать хешмап размера $\mathcal{O}(n)$, и перебирать соответствующее ему $h(v_r)$, назначая вершинам текущего уровня соответствующие классы. Как обычно, если $h(v_r)$ есть в хешмапе, достаем оттуда посчитанный класс, иначе сопоставляем ему новый. 

После того, как классы эквивалентности всех вершин посчитаны, можно освобождать память с предыдущего уровня и переходить к следующему. В конце получим посчитанные классы для всех корней.

Используемое время так и осталось $\mathcal{O}(n^2 \log \sigma)$, а вот требуемая память стала всего $\mathcal{O}(n)$.

Остается открытым вопрос существования более быстрых детерменированных алгоритмов, работающих за $o(n^2 \log \sigma)$, в частности, $\mathcal{O}(n^2)$. К существованию такого алгоритма есть такие предпосылки, как недетерменированные алгоритмы, работающие за $\langle \mathcal{O}(n^2), \mathcal{O}(n) \rangle$.

\subsection{Случай бинарных строк}
% Здесь описываешь алгоритм для бинарных строк
Отдельный интерес представляет случай $\sigma=2$. Есть известный алгоритм, описанный, например, в [1], работающий за время $O(n^2/\log n)$.

В этой же статье рассмотрена задача матожидания длины НОАП двух случайных строк длины $n$ и сделано предположение 5.1 о том, что $LCAF_{avg} \ge n - O(\log n)$. Это преположение выглядит слишком смелым, рассмотрим эту задачу подробнее.


\begin{theorem} %TODO сбилась нумерация теорем :(
Для любой функции $f(n)=o(n)$ верно что для двух случайных бинарных строк длины $n$: $LCAF_{avg} < n - f(n)$.
\end{theorem}
\begin{proof}
%От противного. Предположим, что есть функция $f(n)$ и некоторая константа $\alpha<1$ что $LCAF_{avg} >= n - f(n)$, и $f(n) = o(n^\alpha)$.

Лемма: для любой функции $f(n)=o(n)$ с вероятностью $P>0$ верно $LCAF_{avg} < n - f(n)$.

Обратим внимание, что центральная подстрока длины $n-2f(n)$, полученная отрезанием суффикса и префикса длины $f(n)$, является подстрокой любой строки длины $n-f(n)$ этой же строки.

Рассмотрим задачу как задачу случайного блуждания: пусть $x_i = A_i - B_i$, где $A, B$~--- наши случайные строки. От стандартной задачи случайного блуждания она отличается тем, что кроме переходов $|x_{i+1}-x_i|=1$ разрешены переходы $x_{i+1}=x_i$. Абелево равенство двух подстрок $A$ и $B$ эквивалентно тому, что подпуть блуждания $x$ возвращается в свое начало, $x_r=x_l$.

Наше случайное блуждание имеет следующие вероятности:

\begin{tabular}{|c|c|}
\hline
$\Delta x$ & $p(\Delta x)$ \\
\hline
-1 & 0.25 \\
\hline
0 & 0.5 \\
\hline
1 & 0.25 \\
\hline
\end{tabular}

$P(n, k)$~--- вероятность после $n$ испытаний получить сумму $k$. Можно заметить, что $P(n, k)=C(2n, n+k)\cdot 2^{-2n}$. И действительно, если посмотреть на геометрический смысл этого распределения, то $P(n,k)$~--- вероятность за $2n$ равновероятных шагов вправо или вверх дойти до диагонали $x+y=2n$ и остановиться на диагонали $y-x=k$, что сходится с формулой $P(n,k)=P(n-1,k-1)+2P(n-1,k)+2P(n-1,k+1)$.

При больших $n$ будем приближать наше биномиальное распределение нормальным, $P(n, k)=\sqrt {n} N(0,1)$ %TODO (WARNING, CHECK CONSTANT)

Вспомним о правиле трех сигм:

\begin{figure}[h]
\center{\includegraphics[scale=1]{pics/3sigm.png}}
\caption{правило трех сигм \cite{3}}
\end{figure}

Поскольку у нормального распределения $\sqrt {2n} N(0,1)$ среднеквадратичное отклонение $\sigma = \sqrt{n}$, по правилу трех сигм можно сказать, что у центрального пути длины $n-2f(n)$ вероятность остановиться в промежутке $[-3\sqrt{n-2f(n)}; 3\sqrt{n-2f(n)}]$ около 0.9973, а поскольку $f(n)=o(n)$, вероятность того, что изменение координаты окажется вне промежутка $[-3\sqrt{n}; 3\sqrt{n}]$, хотя бы 0.0026. %TODO (WARNING, считаю, что f(n)=o(n) ---> \_очевидно\_, что можно выкинуть f(n) оттуда)

Для того, чтобы получить отрезок длины $n-f(n)$ с нулевой суммой, нужно взять какой-то суффикс префикса длины $f(n)$ и какой-то префикс суффикса длины $f(n)$. Покажем, что с достаточной вероятностью мы не сможем приблизиться к нулю за $f(n)$ шагов:

Скажем, что наше блуждание сейчас будет обычным случайным, с двумя переходами +1 и -1. Этот переход лишь делает оценку строже, т.к. можно продлить все испытания, в которых был переход по 0 до ровно $k$ ненулевых переходов и прийти к случайному блужданию, при чем максимум модуля отклонения на префиксе мог только увеличиться.

%Есть известный факт, что в случайном блуждании если мы находимся в 0, и заканчиваем, когда попадем в точку с координатой $a$ или $-b$ ($0 < a, b$), то матожидание шагов до этого события $ab$. Воспользуемся этим: матожидание количества шагов до момента, когда мы попадем первый раз в точку $-\sqrt n$ или $\sqrt n$, равно $(\sqrt n)^2=n$. Поскольку матожидание равно $n$, значит существует вероятность $C>0$, с которой весь наш путь из $n$ шагов будет в полосе $(-\sqrt n, \sqrt n)$. %TODO (WARNING, доказательство не оч из-за $C$, надо поаккуратнее)

Поскольку $2f(n)=o(n)$, докажем более сильное условие. За $n$ шагов с вероятностью $C>0$ случайное блуждание не попадет в область с координатой меньше $-\sqrt{n}$. 

Переформулируем эту задачу как задачу о разорении: игрок имеет $\sqrt{n}$ денег и играет $n$ раундов против бесконечно богатого казино, и нужно найти вероятность разорения игрока. В \cite{7} и в \cite{8} можно найти следующую формулу: вероятность проигрыша игрока со стартовым капиталом $a$ за $n$ раундов равна $y_{a,n}=1-{{2} \over {\sqrt{\pi}}} \int_0^t e^{-u^2} du + \Delta$, где $\Delta$~--- малый остаточный член, а $t={{a} \over {\sqrt{2(n+{{2}\over 3})}}}$.

В нашем случае, $a=\sqrt n$, $t \approx {1 \over \sqrt 2}$, и вероятность проигрыша в пределе равна $1 - {2 \over \sqrt \pi}1 \int_0^{1 \over \sqrt 2} e^{-u^2} du \approx 0.395$.

Таким образом, с вероятностью хотя бы 0.0026 центральный подпуть будет иметь отклонение от нуля хотя бы в $3\sqrt n$, и с вероятностью хотя бы $0.395^2$ и префикс, и суффикс, который мы допишем к этой строке, будут иметь отклонение не больше, чем на $\sqrt n$, то есть, с вероятностью $P \ge 0.026 \cdot 0.395^2$ у двух случайных строк наибольшая абелева подстрока будет меньше, чем $n-f(n)$.

Вернемся к доказательству теоремы. Будем доказывать ее от противного~--- пусть есть $f(n)=o(n)$ такое, что $LCAF_{avg} \ge n - f(n)$. 

Оценим $LCAF_{avg}$. По лемме, с вероятностью $P>0$ $LCAF$ будет не больше, чем $g(n)=\sqrt{nf(n)}$. Тогда

$LCAF_{avg} \le P (n-g(n)) + (1-P)n = n-Pg(n) < n - f(n)$, т.к. $f=o(g)$. Противоречие.

\end{proof}

Кроме того, докажем грубую оценку снизу:
\begin{theorem}
Для двух случайных бинарных строк длины $n$: $LCAF_{avg} \ge 0.05n$.
\end{theorem}
\begin{proof}
Снова приблизим наше случайное блуждание нормальным распределением и воспользуемся правилом трех сигм.

С вероятностью $2 \cdot 0.34$ за первые $n/2$ шагов мы остановимся в зоне $[-\sigma; \sigma]$. После этого, с вероятностью хотя бы $0.136+0.021+0.001 \ge 0.15$ мы за следующие $n/2$ шагов пройдем в другую сторону хотя бы $\sigma$ шагов, обязательно перейдя через точку старта. Таким образом, с вероятностью хотя бы $2 \cdot 0.34 \cdot 0.15$ НОАП будет хотя бы $n/2$, или $LCAF_{avg} \ge 0.05$. %TODO может стоит \sigma -> \sqrt

\end{proof}

Итого, получаем, что матожидание НОАП у двух случайных бинарных строк сверху и снизу ограничено линейными функциями, но более точная оценка ее поведения остается нерешенной задачей.

%\end{table}