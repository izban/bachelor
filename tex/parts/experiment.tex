\chapter{Практические результаты}
\section{Параметры компьютера, производящего вычисления}
Все вычисления были выполнены на ноутбуке Acer с процессором Intel(R) Core(TM) i7-4710HQ CPU @ 2.50GHz.

Реализации всех алгоритмов были написаны на языке C++, и были скомпилированы с флагами $-O2$.

\section{Наибольшая общая Абелева подстрока}
\subsection{Случай бинарного алфавита}

Первое, что мы сделаем~--- посмотрим, как себя ведет на практике матожидание наибольшей общей Абелевой подстроки двух случайных бинарных строк. 

Мы выполнили $10^4$ запусков поиска НОАП для различных значений $n$ до $10^4$. Такого количества запусков оказалось вполне достаточно, чтобы среднее значение НОАП стабилизировалось. Полученный результат можно увидеть на рисунке 2.

\begin{figure}[h]
\center{\includegraphics[scale=1]{pics/avlcas.png}}
\caption{зависимость матожидания НОАП от длин строк}
\end{figure}

Видно, что функция ведет себя очень точно как прямая $y=0.83x$, что подтверждает полученные теоретические линейные оценки как сверху, так и снизу.

%\subsection{Общий случай}
%Пусто? Ну я канеш могу закодить то что я придумал но не оч хочется(((

\subsection{Случай большого алфавита}

Будем сравнивать время работы предложенного в этой статье алгоритма за $\mathcal{O}(n^2 \log \sigma)$ с алгоритмом, предложенным A. Attabi et al \cite{1}. Главными достоинствами этого алгоритма является необычайная простота, котороая приводит к очень маленькой константе, скрытой во временной оценке, потому что в нем не используется никаких тяжелых алгоритмов. Алгоритм S. Grabowski et al \cite{4} за $\mathcal{O}
(n^2 \log \sigma)$ имеет такую же временную асимптотику, поэтому с ним сравнение не проводилось: есть все основания полагать, что он работает в несколько (как минимум, в два) раз медленнее из-за эвристик, приводящих к уменьшению потребления памяти.

Так же в процессе анализа я решил не сравнивать с алгоритмом S. Grabowski et al \cite{4} за $\mathcal{O}(n^2 \log^2 n \log^* n)$, потому что в процессе ознакомления с ним я решил, что у него слишком большая скрытая константа~--- алгоритм получен в результате деамортизации недетерменированного, используя для этого довольно тяжелые операции и структуры данных.

В свою очередь, алгоритм, предложенный в этой статье, достаточно тяжелый как в плане написания кода, так и имеет сложно оцениваемую скрытую константы времени работы из-за необходимости очень аккуратно работать с памятью. Представляет большой интерес узнать, является ли данный алгоритм лишь теоретическим улучшением существующих, или он дает ощутимое ускорение на практике.

Сравнение времени работы предложенного алгоритма в зависимости от $n$ на тесте, сгенерированном из двух строк длины $n$, состоящих из случайных символов из алфавита мощности $n$, представлено на рисунке 3.

\begin{figure}[h]
\center{\includegraphics[scale=1]{pics/common_lcas_n.png}}
\caption{Зависимость времени работы алгоритмов от $n$ на случайной строке над большим алфавитом}
\end{figure}

Таким образом, можно с уверенностью сказать, что начиная с не очень большого $n$ предложенный алгоритм начинает сильно выигрывать у стандартной реализации известного алгоритма, и этот выигрыш будет только увеличиваться из-за более хорошей асимптотики.

К сожалению, несмотря на строго более хорошую асимптотику, для маленьких тестовых данных предложенный алгоритм работает несколько медленнее, чем стандартное решение. Это можно объяснить наличием скрытой в асимптотике алгоритма константой, но она достаточно мала, чтобы все равно обеспечить выигрыш на реальных данных.

\section{Количество Абелевых подквадратов}

Далее мы реализовали алгоритм нахождения числа Абелевых подквадратов с помощью сведения к алгоритму решения монотонного ограниченного случая $SUM^+$. Он был протестирован на строках из одинаковых символов, и на наборе пар случайных бинарных строк. Как оказалось, константа алгоритма довольно велика, и на практике он показал себя достаточно плохо, в несколько раз проигрывая наивному решению за $\mathcal{O}(n^2)$.

\begin{figure}[h]
\center{\includegraphics[scale=1]{pics/4.png}}
\caption{зависимость средней времени работы на унарной строке от ее длины}
\end{figure}

На рисунке 3 можно увидеть зависимость времени работы решения в секундах от $n$~--- длины строк, данных на вход, на тесте со строками из одинаковых символов. График действительно довольно похож на $n^{1.86}$, но из-за нескольких логарифмов в асимптотике растет несколько быстрее. 

\begin{figure}[h]
\center{\includegraphics[scale=1]{pics/5.png}}
\caption{зависимость средней времени работы на случайной строке от ее длины}
\end{figure}

На рисунке 4 можно увидеть зависимость времени работы решения в секундах от $n$~--- длины строк, данных на вход, на тесте со случайными строками из двух различных символов.

Время работы алгоритма довольно сильно меняется как от запуска к запуску из-за разных тестов, так и от различных значений $n$, так как различные ветки программы выполняются с разными вероятностями и работают разное время~--- не приходится удивляться некоторому увеличению производительности при увеличении $n$.
